{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import Replicate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import os\n",
    "REPLICATE_API_TOKEN = \"r8_L5qWevfZpFVzXqn8Nu3BT1LrOraGcYB0ldSaF\"\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Replicate(\n",
    "    model=\"meta/meta-llama-3-8b-instruct\", # meta-llama-3-8b-instruct\n",
    "    model_kwargs={\"temperature\": 0, \"max_length\": 200, \"top_p\": 0.5}, # tune?\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/stocks_stats_3.8/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "ReplicateError",
     "evalue": "ReplicateError Details:\ntitle: Free time limit reached\nstatus: 402\ndetail: You have reached the free time limit. To continue using Replicate, set up billing at https://replicate.com/account/billing#billing.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReplicateError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 69\u001b[0m\n\u001b[1;32m     46\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124mTask: Identify Company Tickers and Sentiments\u001b[39m\n\u001b[1;32m     48\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Reminder to only return json. \u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# print(prompt)\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# \"Only print the json. \" messes it up??\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/stocks_stats_3.8/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/stocks_stats_3.8/lib/python3.8/site-packages/langchain_core/language_models/llms.py:1086\u001b[0m, in \u001b[0;36mBaseLLM.__call__\u001b[0;34m(self, prompt, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prompt, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1081\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `prompt` is expected to be a string. Instead found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(prompt)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. If you want to run the LLM on multiple prompts, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1083\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`generate` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1084\u001b[0m     )\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 1086\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m   1096\u001b[0m )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/stocks_stats_3.8/lib/python3.8/site-packages/langchain_core/language_models/llms.py:803\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    790\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    791\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     ]\n\u001b[0;32m--> 803\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/stocks_stats_3.8/lib/python3.8/site-packages/langchain_core/language_models/llms.py:670\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    669\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 670\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    671\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/stocks_stats_3.8/lib/python3.8/site-packages/langchain_core/language_models/llms.py:657\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    649\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    654\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 657\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    665\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    666\u001b[0m         )\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    668\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/stocks_stats_3.8/lib/python3.8/site-packages/langchain_core/language_models/llms.py:1317\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1314\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m   1316\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1317\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1318\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1319\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1320\u001b[0m     )\n\u001b[1;32m   1321\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/stocks_stats_3.8/lib/python3.8/site-packages/langchain_community/llms/replicate.py:140\u001b[0m, in \u001b[0;36mReplicate._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m             completion \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     prediction\u001b[38;5;241m.\u001b[39mwait()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prediction\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/stocks_stats_3.8/lib/python3.8/site-packages/langchain_community/llms/replicate.py:227\u001b[0m, in \u001b[0;36mReplicate._create_prediction\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# if it's an official model\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel:\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreplicate_python\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m replicate_python\u001b[38;5;241m.\u001b[39mpredictions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    230\u001b[0m         version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mversion_obj, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39minput_\n\u001b[1;32m    231\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/stocks_stats_3.8/lib/python3.8/site-packages/replicate/model.py:310\u001b[0m, in \u001b[0;36mModelsPredictions.create\u001b[0;34m(self, model, input, **params)\u001b[0m\n\u001b[1;32m    307\u001b[0m url \u001b[38;5;241m=\u001b[39m _create_prediction_url_from_model(model)\n\u001b[1;32m    308\u001b[0m body \u001b[38;5;241m=\u001b[39m _create_prediction_body(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 310\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _json_to_prediction(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client, resp\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/stocks_stats_3.8/lib/python3.8/site-packages/replicate/client.py:87\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, method, path, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, method: \u001b[38;5;28mstr\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m httpx\u001b[38;5;241m.\u001b[39mResponse:\n\u001b[1;32m     86\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mrequest(method, path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 87\u001b[0m     \u001b[43m_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/stocks_stats_3.8/lib/python3.8/site-packages/replicate/client.py:367\u001b[0m, in \u001b[0;36m_raise_for_status\u001b[0;34m(resp)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_for_status\u001b[39m(resp: httpx\u001b[38;5;241m.\u001b[39mResponse) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m400\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m600\u001b[39m:\n\u001b[0;32m--> 367\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ReplicateError\u001b[38;5;241m.\u001b[39mfrom_response(resp)\n",
      "\u001b[0;31mReplicateError\u001b[0m: ReplicateError Details:\ntitle: Free time limit reached\nstatus: 402\ndetail: You have reached the free time limit. To continue using Replicate, set up billing at https://replicate.com/account/billing#billing."
     ]
    }
   ],
   "source": [
    "\n",
    "# prompt = \"\"\"\n",
    "# Analyze the sentiments relating to each explicitly mentioned company from the news headline in brackets (convert each company to the stock ticker), either positive, neutral, or negative. Return \n",
    "# the answer in json format like the following: {\"ticker\": \"sentiment\"}. \n",
    "# If no companies are explicitly mentioned in the headline, return empty json.\n",
    "# Only include entries in the json if there is specific mention of a company. \n",
    "\n",
    "# [2 Artificial Intelligence (AI) Stocks to Buy Now, and 1 to Avoid Like the Plague]\n",
    "\n",
    "# \"\"\".strip()\n",
    "\n",
    "# prompt = \"\"\"\n",
    "# First, determine the companies mentioned in the news headline in brackets. \n",
    "# Next, determine the sentiment of each company in the news headline (positive, neutral, negative). \n",
    "# Return the answer in json format like the following: {\"ticker\": \"sentiment\"}.\n",
    "# If no companies are explicitly mentioned in the headline, return empty json.\n",
    "\n",
    "# [2 Artificial Intelligence (AI) Stocks to Buy Now, and 1 to Avoid Like the Plague]\n",
    "# Reminder that if one of the subjects of the headline is not a company, do not include it in the json.\n",
    "\n",
    "# \"\"\"\n",
    "# Positive sentiment should indicate that the stock might go up and negative sentiment should indicate that the stock might go down.\n",
    "\n",
    "# !! THIS WORKS\n",
    "# prompt = \"\"\"\n",
    "# First, determine the companies, if any, mentioned in the news headline in brackets and convert them to corresponding stock tickers. \n",
    "# Next, determine the sentiment of each company, if any, in the news headline (positive, neutral, negative). \n",
    "# Return the answer in json format like the following: {\"ticker\": \"sentiment\"}.\n",
    "# If no companies are explicitly mentioned in the headline, return empty json.\n",
    "# If one of the subjects of the headline is not a company, do not include anything related to it in the json.\n",
    "\n",
    "# [Amazon and Microsoft invest in Frances cloud and AI infrastructure]\n",
    "# \"\"\".strip()\n",
    "\n",
    "# prompt = \"\"\"\n",
    "# First, determine the companies, if any, mentioned in the news headline in brackets and convert them to corresponding stock tickers. \n",
    "# Next, determine the sentiment of each company, if any, in the news headline (positive, neutral, negative). \n",
    "# A positive sentiment should indicate that the stock might go up and a negative sentiment should indicate that the stock might go down.\n",
    "# Return the answer in json format like the following: {\"ticker\": \"sentiment\"}.\n",
    "# If no companies are explicitly mentioned in the headline, return empty json.\n",
    "# If one of the subjects of the headline is not a company or you are not sure, exclude from json.\n",
    "\n",
    "# [2 Artificial Intelligence (AI) Stocks to Buy Now, and 1 to Avoid Like the Plague]\n",
    "\n",
    "\n",
    "# \"\"\".strip()\n",
    "prompt = \"\"\"\n",
    "Task: Identify Company Tickers and Sentiments\n",
    "\n",
    "Instructions:\n",
    "1. Given the header provided, identify the names of the companies explicitly mentioned.\n",
    "2. Determine the corresponding ticker symbols for each identified company.\n",
    "3. Assess the sentiment associated with each company (buying or not buying the stock) mentioned in the header (positive, neutral, negative).\n",
    "4. Return the results in JSON format with each company's ticker symbol mapped to its sentiment. Do not include any details beyond this. \n",
    "\n",
    "Do not assume the names of any companies in the header. Only include companies that are explicitly mentioned and exclude all else.\n",
    "\n",
    "Example Input:\n",
    "Header: \"Analysts predict positive outlook for Apple Inc. (AAPL) and minimal growth for Tesla (TSLA).\"\n",
    "\n",
    "Example Output:\n",
    "{\"AAPL\": \"positive\", \"TSLA\": \"negative\"}\n",
    "\n",
    "Header: [2 Artificial Intelligence (AI) Stocks to Buy Now, and 1 to Avoid Like the Plague]\n",
    "\n",
    "\"\"\"\n",
    "# Reminder to only return json. \n",
    "# print(prompt)\n",
    "# \"Only print the json. \" messes it up??\n",
    "print(llm(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bad prompts\n",
    "2 Artificial Intelligence (AI) Stocks to Buy Now, and 1 to Avoid Like the Plague\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv called sentiment_score.csv\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"sentiment_score.csv\")\n",
    "# get headline column\n",
    "headlines = df[\"headline\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_companylist = f\"\"\"\n",
    "Tell me the tickers of the companies mentioned in the following headline. If there are no companies, return empty list.\n",
    "[]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSFT'] headline: Microsoft pledges $4.3 billion investment at Macrons Choose France summit <class 'str'>\n",
      "['PDD', 'INTC', 'ARMH', 'MSFT'] headline: PDD, Intel, Arm, Microsoft, and Other Tech Stocks in Focus Today <class 'str'>\n",
      "['DVY'] headline: 1 Top Dividend Growth ETF to Buy and Hold for 10 Years <class 'str'>\n",
      "['MSFT'] headline: Microsoft Corp: An Exploration into Its Intrinsic Value <class 'str'>\n",
      "['AMZN', 'MSFT'] headline: Amazon and Microsoft invest in Frances cloud and AI infrastructure <class 'str'>\n",
      "[] headline: 5 Things to Know Before the Stock Market Opens <class 'str'>\n",
      "['DVY', 'VYM', 'NOBL', 'SDY', 'PEY', 'PGX', 'FVD', 'VIG', 'HDV', 'SPHD', 'SDP', 'PEK'] headline: 12 Monthly Dividend Stocks with Over 5% Yield <class 'str'>\n",
      "['GME'] headline: GameStop surges, Wall Street eyes Inflation data:Yahoo Finance <class 'str'>\n",
      "['MSFT'] headline: Market Chatter: European Commission Reportedly Set to Issue Antitrust Charges Against Microsoft Over Teams, Software Bundling <class 'str'>\n",
      "['MSFT'] headline: Market Chatter: Microsoft to Invest $4.31 Billion in Cloud, AI Infrastructure in France <class 'str'>\n",
      "['AAPL', 'MSFT', 'JPM', 'V', 'PG', 'MCD', 'CSCO'] headline: 7 Blue-Chip Stock Beauties to Bet on in May <class 'str'>\n",
      "['GME', 'AMC'] headline: Social Buzz: Wallstreetbets Stocks Mostly Higher Premarket Monday; GameStop, AMC Entertainment to Advance <class 'str'>\n",
      "['MSFT', 'ADBE', 'SAP'] headline: The 3 Most Undervalued Software Stocks to Buy in May 2024 <class 'str'>\n",
      "[] headline: US STOCKS-Futures edge higher at start of data-heavy week <class 'str'>\n",
      "['AAPL', 'AMZN', 'GOOGL', 'MSFT', 'TSLA', 'V', 'JPM'] headline: The 7 Most Undervalued Stocks With Strong Fundamentals to Buy in May 2024 <class 'str'>\n",
      "['MSFT'] headline: Microsoft to invest 4 billion in French cloud and AI services <class 'str'>\n",
      "[] headline: Taiwan should redefine the value of its supply chain <class 'str'>\n",
      "['FR'] headline: UPDATE 2-'Choose France' investment push bags record $16 billion in pledges <class 'str'>\n",
      "['MSFT'] headline: Microsoft to invest 4 billion euros in France <class 'str'>\n",
      "['ARM'] headline: Arm Stock in Focus After Reportedly Planning to Launch AI Chips <class 'str'>\n",
      "['MSFT', 'GOOGL', 'AMZN'] headline: Prediction: This Artificial Intelligence (AI) Cloud Stock Will Join Microsoft, Alphabet, and Amazon in the $1 Trillion Club <class 'str'>\n",
      "['FIS'] headline: Billionaire Ken Fisher Loves These 5 AI Stocks <class 'str'>\n",
      "[] headline: 15 Jobs That Will Be in Demand in 2030 <class 'str'>\n",
      "['JAMF'] headline: Jamf Holding Corp. (NASDAQ:JAMF) Q1 2024 Earnings Call Transcript <class 'str'>\n",
      "['CSPI'] headline: CSP Inc. (NASDAQ:CSPI) Q2 2024 Earnings Call Transcript <class 'str'>\n",
      "['AAPL'] headline: Here's 1 big investing mistake you are probably still making <class 'str'>\n",
      "['AI', 'PLUG'] headline: 2 Artificial Intelligence (AI) Stocks to Buy Now, and 1 to Avoid Like the Plague <class 'str'>\n",
      "['AMZN'] headline: A Once-in-a-Generation Investment Opportunity: 50 Billion Reasons Why Amazon's Story Just Keeps Getting Better. <class 'str'>\n",
      "[AAPL] headline: AAPL Analysis: Why Apple Stock Dipped in Q2 and What's Ahead for Q3 <class 'str'>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'AAPL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(output, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheadline:\u001b[39m\u001b[38;5;124m\"\u001b[39m, headline, \u001b[38;5;28mtype\u001b[39m(output))\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Review the headline again and confirm to yourself that the companies exist and sentiment is correct for the headline. Only print the json. \u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m output_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# break\u001b[39;00m\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AAPL' is not defined"
     ]
    }
   ],
   "source": [
    "for headline in headlines:\n",
    "    # print(\"headline\", headline)\n",
    "    example = \"{\\\"TSLA\\\": \\\"positive\\\"}\"\n",
    "\n",
    "    # prompt = f\"\"\"\n",
    "    # Analyze the sentiments relating to each explicitly mentioned company from the news headline (convert each company to the stock ticker), either positive, neutral, or negative. Return \n",
    "    # the answer in only json format like the following: {example}. \n",
    "    # If there is no explicit mention of companies, do not include in the json \n",
    "    # or return empty json if there are no companies at all.\n",
    "\n",
    "    # [{headline}]\n",
    "    # Review the headline again and confirm to yourself that the companies exist and sentiment is correct for the headline. Only print the json. \n",
    "\n",
    "    # \"\"\".strip()\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in the names of all companies on the stock market. \n",
    "    Return the ticker of the companies mentioned in the following headline. \n",
    "    If there are no companies, return empty list. Only return the list. \n",
    "    [{headline}]\n",
    "    \"\"\".strip()\n",
    "\n",
    "    \n",
    "\n",
    "    output = llm(prompt)\n",
    "    # convert string output to json\n",
    "    # print()\n",
    "    print(output, \"headline:\", headline, type(output))\n",
    "    # Review the headline again and confirm to yourself that the companies exist and sentiment is correct for the headline. Only print the json. \n",
    "    output_json = eval(output)\n",
    "    \n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stocks_stats_3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
